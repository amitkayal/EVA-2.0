{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA_assignment4.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwBoom07NDhm",
        "colab_type": "text"
      },
      "source": [
        "# FIRST CODE\n",
        "This is the vanilla coda that is executed without any additional layers other than Convolution. \n",
        "\n",
        "In this code, I'm using just, Conv2D, Max Pooling and 1x1. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnhtKVFLb3PG",
        "colab_type": "text"
      },
      "source": [
        "# Importing the required libraries and required modules\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmV3T8RMHe4f",
        "colab_type": "code",
        "outputId": "b5c7d6ba-7f78-4c21-d2e0-97514df37947",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtFRE2HcIK3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.layers import Activation, Flatten, Add, BatchNormalization, Convolution2D, MaxPooling2D,Dropout\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist\n",
        "\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmgElg1IN0at",
        "colab_type": "text"
      },
      "source": [
        "### Loading the MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYB6naGTMd3h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a037fd85-219c-4302-d410-f68b5ba32217"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSpJysQBOEsc",
        "colab_type": "code",
        "outputId": "921c4786-69ce-4a0a-9777-8a3fcced179f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.imshow(x_train[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb469da39e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADoBJREFUeJzt3X2MXOV1x/HfyXq9jo1JvHHYboiL\nHeMEiGlMOjIgLKCiuA5CMiiKiRVFDiFxmuCktK4EdavGrWjlVgmRQynS0ri2I95CAsJ/0CR0FUGi\nwpbFMeYtvJlNY7PsYjZgQ4i9Xp/+sdfRBnaeWc/cmTu75/uRVjtzz71zj6792zszz8x9zN0FIJ53\nFd0AgGIQfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQU1r5M6mW5vP0KxG7hII5bd6U4f9kE1k\n3ZrCb2YrJG2W1CLpP9x9U2r9GZqls+2iWnYJIKHHuye8btVP+82sRdJNkj4h6QxJq83sjGofD0Bj\n1fKaf6mk5919j7sflnSHpJX5tAWg3moJ/8mSfjXm/t5s2e8xs7Vm1mtmvcM6VMPuAOSp7u/2u3uX\nu5fcvdSqtnrvDsAE1RL+fZLmjbn/wWwZgEmglvA/ImmRmS0ws+mSPi1pRz5tAai3qof63P2Ima2T\n9CONDvVtcfcnc+sMQF3VNM7v7vdJui+nXgA0EB/vBYIi/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q\nFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/\nEBThB4Ii/EBQhB8IivADQRF+IKiaZuk1sz5JByWNSDri7qU8mkJ+bFr6n7jl/XPruv9n/np+2drI\nzKPJbU9ZOJisz/yKJesv3zC9bG1n6c7ktvtH3kzWz75rfbJ+6l89nKw3g5rCn/kTd9+fw+MAaCCe\n9gNB1Rp+l/RjM3vUzNbm0RCAxqj1af8yd99nZidJut/MfuHuD45dIfujsFaSZmhmjbsDkJeazvzu\nvi/7PSjpHklLx1mny91L7l5qVVstuwOQo6rDb2azzGz2sduSlkt6Iq/GANRXLU/7OyTdY2bHHuc2\nd/9hLl0BqLuqw+/ueyR9LMdepqyW0xcl697Wmqy/dMF7k/W3zik/Jt3+nvR49U8/lh7vLtJ//WZ2\nsv4v/7YiWe8587aytReH30puu2ng4mT9Az/1ZH0yYKgPCIrwA0ERfiAowg8ERfiBoAg/EFQe3+oL\nb+TCjyfrN2y9KVn/cGv5r55OZcM+kqz//Y2fS9anvZkebjv3rnVla7P3HUlu27Y/PRQ4s7cnWZ8M\nOPMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCM8+eg7ZmXkvVHfzsvWf9w60Ce7eRqff85yfqeN9KX\n/t668Ptla68fTY/Td3z7f5L1epr8X9itjDM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRl7o0b0TzR\n2v1su6hh+2sWQ1eem6wfWJG+vHbL7hOS9ce+cuNx93TM9fv/KFl/5IL0OP7Ia68n635u+au7930t\nuakWrH4svQLeoce7dcCH0nOXZzjzA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQFcf5zWyLpEslDbr7\n4mxZu6Q7Jc2X1Cdplbv/utLOoo7zV9Iy933J+sirQ8n6i7eVH6t/8vwtyW2X/vNXk/WTbiruO/U4\nfnmP82+V9PaJ0K+T1O3uiyR1Z/cBTCIVw+/uD0p6+6lnpaRt2e1tki7LuS8AdVbta/4Od+/Pbr8s\nqSOnfgA0SM1v+PnomwZl3zgws7Vm1mtmvcM6VOvuAOSk2vAPmFmnJGW/B8ut6O5d7l5y91Kr2qrc\nHYC8VRv+HZLWZLfXSLo3n3YANErF8JvZ7ZIekvQRM9trZldJ2iTpYjN7TtKfZvcBTCIVr9vv7qvL\nlBiwz8nI/ldr2n74wPSqt/3oZ55K1l+5uSX9AEdHqt43isUn/ICgCD8QFOEHgiL8QFCEHwiK8ANB\nMUX3FHD6tc+WrV15ZnpE9j9P6U7WL/jU1cn67DsfTtbRvDjzA0ERfiAowg8ERfiBoAg/EBThB4Ii\n/EBQjPNPAalpsl/98unJbf9vx1vJ+nXXb0/W/2bV5cm6//w9ZWvz/umh5LZq4PTxEXHmB4Ii/EBQ\nhB8IivADQRF+ICjCDwRF+IGgKk7RnSem6G4+Q58/N1m/9evfSNYXTJtR9b4/un1dsr7olv5k/cie\nvqr3PVXlPUU3gCmI8ANBEX4gKMIPBEX4gaAIPxAU4QeCqjjOb2ZbJF0qadDdF2fLNkr6oqRXstU2\nuPt9lXbGOP/k4+ctSdZP3LQ3Wb/9Qz+qet+n/eQLyfpH/qH8dQwkaeS5PVXve7LKe5x/q6QV4yz/\nlrsvyX4qBh9Ac6kYfnd/UNJQA3oB0EC1vOZfZ2a7zWyLmc3JrSMADVFt+G+WtFDSEkn9kr5ZbkUz\nW2tmvWbWO6xDVe4OQN6qCr+7D7j7iLsflXSLpKWJdbvcveTupVa1VdsngJxVFX4z6xxz93JJT+TT\nDoBGqXjpbjO7XdKFkuaa2V5JX5d0oZktkeSS+iR9qY49AqgDvs+PmrR0nJSsv3TFqWVrPdduTm77\nrgpPTD/z4vJk/fVlrybrUxHf5wdQEeEHgiL8QFCEHwiK8ANBEX4gKIb6UJjv7U1P0T3Tpifrv/HD\nyfqlX72m/GPf05PcdrJiqA9ARYQfCIrwA0ERfiAowg8ERfiBoAg/EFTF7/MjtqPL0pfufuFT6Sm6\nFy/pK1urNI5fyY1DZyXrM+/trenxpzrO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOP8U5yVFifr\nz34tPdZ+y3nbkvXzZ6S/U1+LQz6crD88tCD9AEf7c+xm6uHMDwRF+IGgCD8QFOEHgiL8QFCEHwiK\n8ANBVRznN7N5krZL6pDkkrrcfbOZtUu6U9J8SX2SVrn7r+vXalzTFpySrL9w5QfK1jZecUdy20+e\nsL+qnvKwYaCUrD+w+Zxkfc629HX/kTaRM/8RSevd/QxJ50i62szOkHSdpG53XySpO7sPYJKoGH53\n73f3ndntg5KelnSypJWSjn38a5uky+rVJID8HddrfjObL+ksST2SOtz92OcnX9boywIAk8SEw29m\nJ0j6gaRr3P3A2JqPTvg37qR/ZrbWzHrNrHdYh2pqFkB+JhR+M2vVaPBvdfe7s8UDZtaZ1TslDY63\nrbt3uXvJ3UutasujZwA5qBh+MzNJ35H0tLvfMKa0Q9Ka7PYaSffm3x6AepnIV3rPk/RZSY+b2a5s\n2QZJmyR9z8yukvRLSavq0+LkN23+Hybrr/9xZ7J+xT/+MFn/8/fenazX0/r+9HDcQ/9efjivfev/\nJredc5ShvHqqGH53/5mkcvN9X5RvOwAahU/4AUERfiAowg8ERfiBoAg/EBThB4Li0t0TNK3zD8rW\nhrbMSm775QUPJOurZw9U1VMe1u1blqzvvDk9Rffc7z+RrLcfZKy+WXHmB4Ii/EBQhB8IivADQRF+\nICjCDwRF+IGgwozzH/6z9GWiD//lULK+4dT7ytaWv/vNqnrKy8DIW2Vr5+9Yn9z2tL/7RbLe/lp6\nnP5osopmxpkfCIrwA0ERfiAowg8ERfiBoAg/EBThB4IKM87fd1n679yzZ95Vt33f9NrCZH3zA8uT\ndRspd+X0Uadd/2LZ2qKBnuS2I8kqpjLO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QlLl7egWzeZK2\nS+qQ5JK63H2zmW2U9EVJr2SrbnD38l96l3SitfvZxqzeQL30eLcO+FD6gyGZiXzI54ik9e6+08xm\nS3rUzO7Pat9y929U2yiA4lQMv7v3S+rPbh80s6clnVzvxgDU13G95jez+ZLOknTsM6PrzGy3mW0x\nszlltllrZr1m1jusQzU1CyA/Ew6/mZ0g6QeSrnH3A5JulrRQ0hKNPjP45njbuXuXu5fcvdSqthxa\nBpCHCYXfzFo1Gvxb3f1uSXL3AXcfcfejkm6RtLR+bQLIW8Xwm5lJ+o6kp939hjHLO8esdrmk9HSt\nAJrKRN7tP0/SZyU9bma7smUbJK02syUaHf7rk/SlunQIoC4m8m7/zySNN26YHNMH0Nz4hB8QFOEH\ngiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCoipfuznVnZq9I+uWY\nRXMl7W9YA8enWXtr1r4keqtWnr2d4u7vn8iKDQ3/O3Zu1uvupcIaSGjW3pq1L4neqlVUbzztB4Ii\n/EBQRYe/q+D9pzRrb83al0Rv1Sqkt0Jf8wMoTtFnfgAFKST8ZrbCzJ4xs+fN7LoieijHzPrM7HEz\n22VmvQX3ssXMBs3siTHL2s3sfjN7Lvs97jRpBfW20cz2Zcdul5ldUlBv88zsJ2b2lJk9aWZ/kS0v\n9Ngl+irkuDX8ab+ZtUh6VtLFkvZKekTSand/qqGNlGFmfZJK7l74mLCZnS/pDUnb3X1xtuxfJQ25\n+6bsD+ccd7+2SXrbKOmNomduziaU6Rw7s7SkyyR9TgUeu0Rfq1TAcSvizL9U0vPuvsfdD0u6Q9LK\nAvpoeu7+oKShty1eKWlbdnubRv/zNFyZ3pqCu/e7+87s9kFJx2aWLvTYJfoqRBHhP1nSr8bc36vm\nmvLbJf3YzB41s7VFNzOOjmzadEl6WVJHkc2Mo+LMzY30tpmlm+bYVTPjdd54w++dlrn7xyV9QtLV\n2dPbpuSjr9maabhmQjM3N8o4M0v/TpHHrtoZr/NWRPj3SZo35v4Hs2VNwd33Zb8HJd2j5pt9eODY\nJKnZ78GC+/mdZpq5ebyZpdUEx66ZZrwuIvyPSFpkZgvMbLqkT0vaUUAf72Bms7I3YmRmsyQtV/PN\nPrxD0prs9hpJ9xbYy+9plpmby80srYKPXdPNeO3uDf+RdIlG3/F/QdLfFtFDmb4+JOmx7OfJonuT\ndLtGnwYOa/S9kaskvU9St6TnJP23pPYm6u27kh6XtFujQessqLdlGn1Kv1vSruznkqKPXaKvQo4b\nn/ADguINPyAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQf0/sEWOix6VKakAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLqYK-gPO3lO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain = x_train.reshape(x_train.shape[0], 28, 28,1)\n",
        "xtest = x_test.reshape(x_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt_IjXh_O6lA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain = xtrain.astype('float32')\n",
        "xtest = xtest.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn3t-p2HPDiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain /= 255.0\n",
        "xtest /= 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdlbHUtbPPCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ytrain = np_utils.to_categorical(y_train, 10)\n",
        "ytest = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qta0SDv7Xjbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(28,28,1))) # 28\n",
        "model.add(Convolution2D(64, (3, 3), activation='relu')) # 26 \n",
        "model.add(Convolution2D(32, 1, activation='relu')) # 26\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(32, (3, 3), activation='relu')) # 11\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(32, (3, 3), activation='relu')) # 9\n",
        "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
        "model.add(Convolution2D(10, 1))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm0M_k0jYZTg",
        "colab_type": "code",
        "outputId": "ad7f8d63-6098-4468-9041-955b6b7ca8da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 24, 24, 32)        2080      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 10, 10, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 3, 3, 32)          9248      \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 1, 1, 64)          18496     \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 1, 1, 10)          650       \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 58,538\n",
            "Trainable params: 58,538\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGDMWxN0YaaL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "075a8546-d3e2-4e1d-fccf-002c97c7a064"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0811 14:34:43.923436 140414239795072 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0811 14:34:43.958455 140414239795072 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KjFzNj8ZII9",
        "colab_type": "code",
        "outputId": "48d82c53-29e0-4548-9c6f-5a3becd45292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(xtrain, ytrain, batch_size=32, nb_epoch=30, verbose=1, validation_data=(xtest, ytest))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "W0811 14:34:44.727239 140414239795072 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0811 14:34:44.828400 140414239795072 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 31s 517us/step - loss: 0.1619 - acc: 0.9505 - val_loss: 0.0523 - val_acc: 0.9826\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 26s 426us/step - loss: 0.0518 - acc: 0.9841 - val_loss: 0.0561 - val_acc: 0.9817\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 26s 427us/step - loss: 0.0387 - acc: 0.9881 - val_loss: 0.0295 - val_acc: 0.9898\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 26s 426us/step - loss: 0.0324 - acc: 0.9897 - val_loss: 0.0303 - val_acc: 0.9896\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 25s 424us/step - loss: 0.0263 - acc: 0.9916 - val_loss: 0.0298 - val_acc: 0.9901\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 25s 423us/step - loss: 0.0217 - acc: 0.9929 - val_loss: 0.0292 - val_acc: 0.9901\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 25s 414us/step - loss: 0.0192 - acc: 0.9937 - val_loss: 0.0401 - val_acc: 0.9878\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 25s 415us/step - loss: 0.0172 - acc: 0.9946 - val_loss: 0.0400 - val_acc: 0.9876\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 25s 412us/step - loss: 0.0135 - acc: 0.9959 - val_loss: 0.0279 - val_acc: 0.9908\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.0133 - acc: 0.9957 - val_loss: 0.0340 - val_acc: 0.9908\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.0113 - acc: 0.9963 - val_loss: 0.0295 - val_acc: 0.9923\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.0099 - acc: 0.9967 - val_loss: 0.0394 - val_acc: 0.9904\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.0107 - acc: 0.9964 - val_loss: 0.0369 - val_acc: 0.9906\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0098 - acc: 0.9968 - val_loss: 0.0374 - val_acc: 0.9896\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0087 - acc: 0.9971 - val_loss: 0.0271 - val_acc: 0.9934\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0078 - acc: 0.9974 - val_loss: 0.0327 - val_acc: 0.9917\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0084 - acc: 0.9975 - val_loss: 0.0280 - val_acc: 0.9923\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.0074 - acc: 0.9976 - val_loss: 0.0292 - val_acc: 0.9932\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 25s 409us/step - loss: 0.0072 - acc: 0.9978 - val_loss: 0.0310 - val_acc: 0.9906\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.0065 - acc: 0.9979 - val_loss: 0.0458 - val_acc: 0.9910\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0069 - acc: 0.9977 - val_loss: 0.0494 - val_acc: 0.9905\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.0532 - val_acc: 0.9904\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 24s 403us/step - loss: 0.0071 - acc: 0.9976 - val_loss: 0.0378 - val_acc: 0.9921\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.0061 - acc: 0.9982 - val_loss: 0.0370 - val_acc: 0.9917\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.0072 - acc: 0.9976 - val_loss: 0.0403 - val_acc: 0.9919\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.0061 - acc: 0.9981 - val_loss: 0.0343 - val_acc: 0.9917\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0433 - val_acc: 0.9914\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0057 - acc: 0.9982 - val_loss: 0.0490 - val_acc: 0.9890\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.0051 - acc: 0.9984 - val_loss: 0.0562 - val_acc: 0.9900\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.0071 - acc: 0.9981 - val_loss: 0.0490 - val_acc: 0.9912\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb466ad39b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24UYWhFcZJhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(xtest, ytest, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fItOD1KJgHN_",
        "colab_type": "code",
        "outputId": "50f92611-7ae9-424a-857a-408e86d10ea0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.049034275156660374, 0.9912]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ptdmah5yJlbJ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5zcNaDTJn_c",
        "colab_type": "text"
      },
      "source": [
        "# SECOND CODE\n",
        "In this code, there is addition of Batch Normalization and Introduction of Variations in the number of Parameters. So the three changes from the vanilla code are:\n",
        "\n",
        "\n",
        "*  Addition of Batch Normalization\n",
        "*  Changes in the number of channels\n",
        "*   Changes in the batch size\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT6Nmt3HgJEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_lik_m0KgMe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "1f086e63-ae76-496f-b7a6-9d478bf1ca75"
      },
      "source": [
        "\n",
        "plt.imshow(x_train[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb46650da20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAdhv2OTKq_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain = x_train.reshape(x_train.shape[0], 28, 28,1)\n",
        "xtest = x_test.reshape(x_test.shape[0], 28, 28,1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG6yq9tKKxBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain = xtrain.astype('float32')\n",
        "xtest = xtest.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIc7q9RPKz-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain /= 255.0\n",
        "xtest /= 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WboJI3XqK2Ge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ytrain = np_utils.to_categorical(y_train, 10)\n",
        "ytest = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giKpZCWyK3vk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "490f8e79-392f-4449-b669-73f47e4af43b"
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(16, 1, 1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(16, 1, 1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(10, 1, 1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1))`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkJeGZDDK7Xb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "outputId": "65290543-cfc0-4cfa-993a-f5a979e817be"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_22 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 26, 26, 16)        272       \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 13, 13, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 11, 11, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 11, 11, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 11, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 11, 11, 16)        528       \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 11, 11, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 3, 3, 32)          4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 3, 3, 32)          128       \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 3, 3, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 1, 1, 16)          4624      \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 1, 1, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 1, 1, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 1, 1, 10)          170       \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 15,586\n",
            "Trainable params: 15,310\n",
            "Non-trainable params: 276\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0Itb3bULB1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU-3KGkHLIEX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "ce6a1759-c7b5-4c8e-9c64-cbbebde85a88"
      },
      "source": [
        "model.fit(xtrain, ytrain, batch_size=128, nb_epoch=10, verbose=1, validation_data=(xtest, ytest))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.5421 - acc: 0.9254 - val_loss: 0.2906 - val_acc: 0.9743\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 9s 157us/step - loss: 0.1878 - acc: 0.9814 - val_loss: 0.1289 - val_acc: 0.9879\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.1134 - acc: 0.9869 - val_loss: 0.0830 - val_acc: 0.9883\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.0808 - acc: 0.9896 - val_loss: 0.0641 - val_acc: 0.9919\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.0605 - acc: 0.9920 - val_loss: 0.0562 - val_acc: 0.9908\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.0485 - acc: 0.9927 - val_loss: 0.0646 - val_acc: 0.9880\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.0399 - acc: 0.9935 - val_loss: 0.0386 - val_acc: 0.9919\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.0338 - acc: 0.9941 - val_loss: 0.0434 - val_acc: 0.9893\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.0295 - acc: 0.9943 - val_loss: 0.0341 - val_acc: 0.9906\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.0245 - acc: 0.9956 - val_loss: 0.0380 - val_acc: 0.9901\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb41a4b84a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePNGqtKgLL1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(xtest, ytest, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiiFR9uGLtf5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5b90823-5f66-4d60-fce6-87dadc3fa859"
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.03798307363688946, 0.9901]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a4proNoL08y",
        "colab_type": "text"
      },
      "source": [
        "## Observations\n",
        "In this network the number of parameters have reduced to around 15k and using 10 epochs 99.01% accuracy is achieved without overfitting. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFOaeHAfMJZl",
        "colab_type": "text"
      },
      "source": [
        "# THIRD CODE \n",
        "The three changes from the second code are:\n",
        "\n",
        "* Addition of Dropout\n",
        "* Change of Optimizer from adam to SGD\n",
        "* Change in learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuRltOUnLvSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU154mofM5-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain = x_train.reshape(x_train.shape[0], 28, 28,1)\n",
        "xtest = x_test.reshape(x_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UUeLfiCM7_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain = xtrain.astype('float32')\n",
        "xtest = xtest.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8jKAaRgM99Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain /= 255.0\n",
        "xtest /= 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paOCnqanM_sX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ytrain = np_utils.to_categorical(y_train, 10)\n",
        "ytest = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTQxEzRENCSp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "70b526ca-5775-4ce5-e11c-d3e195309661"
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(10, 1, 1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(10, 1, 1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(10, 1, 1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1))`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jrmdiKENorL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "221f8b80-ba2c-4c2f-a800-02e42813ff6d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_36 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_26 (Activation)   (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 26, 26, 10)        170       \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "activation_27 (Activation)   (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 13, 13, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 11, 11, 32)        2912      \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 11, 11, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 11, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 11, 11, 10)        330       \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 11, 11, 10)        40        \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 5, 5, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 3, 3, 32)          2912      \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 3, 3, 32)          128       \n",
            "_________________________________________________________________\n",
            "activation_30 (Activation)   (None, 3, 3, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 1, 1, 16)          4624      \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 1, 1, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_31 (Activation)   (None, 1, 1, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 1, 1, 10)          170       \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "activation_32 (Activation)   (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_33 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 11,782\n",
            "Trainable params: 11,530\n",
            "Non-trainable params: 252\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hesb1K0eNvFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "sgd = keras.optimizers.sgd(lr=0.001)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=sgd,\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5OsQFEwNytA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d75ecca7-9c50-404a-94df-68361536d45b"
      },
      "source": [
        "model.fit(xtrain, ytrain, batch_size=32, nb_epoch=30, verbose=1, validation_data=(xtest, ytest))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 29s 484us/step - loss: 1.4590 - acc: 0.6264 - val_loss: 1.2470 - val_acc: 0.8294\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 27s 450us/step - loss: 0.8957 - acc: 0.8532 - val_loss: 0.9804 - val_acc: 0.8936\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 27s 452us/step - loss: 0.6968 - acc: 0.8898 - val_loss: 0.7915 - val_acc: 0.9205\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 27s 452us/step - loss: 0.5818 - acc: 0.9048 - val_loss: 0.6664 - val_acc: 0.9331\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 27s 451us/step - loss: 0.5031 - acc: 0.9149 - val_loss: 0.5675 - val_acc: 0.9409\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 27s 452us/step - loss: 0.4443 - acc: 0.9226 - val_loss: 0.4992 - val_acc: 0.9469\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 27s 450us/step - loss: 0.3989 - acc: 0.9290 - val_loss: 0.4391 - val_acc: 0.9528\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 27s 451us/step - loss: 0.3674 - acc: 0.9334 - val_loss: 0.3941 - val_acc: 0.9565\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 27s 451us/step - loss: 0.3415 - acc: 0.9352 - val_loss: 0.3698 - val_acc: 0.9578\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 27s 450us/step - loss: 0.3145 - acc: 0.9397 - val_loss: 0.3339 - val_acc: 0.9610\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 27s 449us/step - loss: 0.2947 - acc: 0.9424 - val_loss: 0.2971 - val_acc: 0.9651\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 27s 457us/step - loss: 0.2820 - acc: 0.9446 - val_loss: 0.2799 - val_acc: 0.9669\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 27s 448us/step - loss: 0.2670 - acc: 0.9460 - val_loss: 0.2478 - val_acc: 0.9709\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 27s 444us/step - loss: 0.2547 - acc: 0.9488 - val_loss: 0.2455 - val_acc: 0.9691\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 27s 448us/step - loss: 0.2413 - acc: 0.9506 - val_loss: 0.2212 - val_acc: 0.9726\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 27s 448us/step - loss: 0.2353 - acc: 0.9507 - val_loss: 0.2138 - val_acc: 0.9712\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 27s 449us/step - loss: 0.2245 - acc: 0.9534 - val_loss: 0.1977 - val_acc: 0.9737\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 27s 448us/step - loss: 0.2191 - acc: 0.9544 - val_loss: 0.1907 - val_acc: 0.9746\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 27s 448us/step - loss: 0.2096 - acc: 0.9565 - val_loss: 0.1844 - val_acc: 0.9744\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 27s 449us/step - loss: 0.2050 - acc: 0.9556 - val_loss: 0.1747 - val_acc: 0.9749\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 27s 449us/step - loss: 0.1995 - acc: 0.9572 - val_loss: 0.1637 - val_acc: 0.9759\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 27s 451us/step - loss: 0.1913 - acc: 0.9582 - val_loss: 0.1631 - val_acc: 0.9765\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 27s 456us/step - loss: 0.1826 - acc: 0.9600 - val_loss: 0.1582 - val_acc: 0.9766\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 27s 451us/step - loss: 0.1812 - acc: 0.9597 - val_loss: 0.1501 - val_acc: 0.9778\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 27s 450us/step - loss: 0.1786 - acc: 0.9616 - val_loss: 0.1447 - val_acc: 0.9778\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 27s 450us/step - loss: 0.1749 - acc: 0.9608 - val_loss: 0.1392 - val_acc: 0.9783\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 27s 449us/step - loss: 0.1717 - acc: 0.9615 - val_loss: 0.1337 - val_acc: 0.9792\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 27s 450us/step - loss: 0.1684 - acc: 0.9624 - val_loss: 0.1334 - val_acc: 0.9798\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 27s 448us/step - loss: 0.1631 - acc: 0.9639 - val_loss: 0.1297 - val_acc: 0.9793\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 27s 451us/step - loss: 0.1607 - acc: 0.9641 - val_loss: 0.1244 - val_acc: 0.9802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb4181eacf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmpiCugcN3vK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "f0ed0f7e-9936-4eb1-a351-1e967f0456c2"
      },
      "source": [
        "model.fit(xtrain, ytrain, batch_size=32, nb_epoch=10, verbose=1, validation_data=(xtest, ytest))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "  384/60000 [..............................] - ETA: 30s - loss: 0.1751 - acc: 0.9453"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 27s 450us/step - loss: 0.1588 - acc: 0.9634 - val_loss: 0.1201 - val_acc: 0.9799\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 27s 450us/step - loss: 0.1554 - acc: 0.9653 - val_loss: 0.1239 - val_acc: 0.9788\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 27s 451us/step - loss: 0.1531 - acc: 0.9654 - val_loss: 0.1155 - val_acc: 0.9796\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 27s 452us/step - loss: 0.1472 - acc: 0.9666 - val_loss: 0.1112 - val_acc: 0.9809\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 27s 453us/step - loss: 0.1445 - acc: 0.9684 - val_loss: 0.1129 - val_acc: 0.9799\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 27s 445us/step - loss: 0.1413 - acc: 0.9678 - val_loss: 0.1074 - val_acc: 0.9810\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 27s 449us/step - loss: 0.1429 - acc: 0.9677 - val_loss: 0.1026 - val_acc: 0.9814\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 27s 448us/step - loss: 0.1395 - acc: 0.9698 - val_loss: 0.1037 - val_acc: 0.9812\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 27s 449us/step - loss: 0.1367 - acc: 0.9692 - val_loss: 0.1065 - val_acc: 0.9807\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 27s 449us/step - loss: 0.1350 - acc: 0.9687 - val_loss: 0.0986 - val_acc: 0.9817\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb4181c6668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWLOmSSJWIvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(xtest, ytest, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThMzcJIqXICw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a75eee7-7c2c-471e-bec7-d648b4bdd018"
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.09861868968009949, 0.9817]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKfrVDnsXOii",
        "colab_type": "text"
      },
      "source": [
        "## Observations\n",
        "* Number of parameters further reduced to 11k.\n",
        "* The model did not overfit because of Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tlVxOboXdQ0",
        "colab_type": "text"
      },
      "source": [
        "# FOURTH CODE\n",
        "\n",
        "The changes made here from the third code are:\n",
        "* Add Dropout after every layer\n",
        "* Add scheduler to change learning rate after every iteration.\n",
        "* Introduce callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1GR2g1NXKb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0yUeONcX_tc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain = x_train.reshape(x_train.shape[0], 28, 28,1)\n",
        "xtest = x_test.reshape(x_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi1DDqUSYCE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain = xtrain.astype('float32')\n",
        "xtest = xtest.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTVFq6ePYD-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain /= 255.0\n",
        "xtest /= 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biJ1BIqLYF6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ytrain = np_utils.to_categorical(y_train, 10)\n",
        "ytest = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0KiQ3dIYIgp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "9b7cfca1-7daf-48ea-832e-49a2ae48f45f"
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 1, 1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(14, 3, 3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(12, 3, 3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 7, 7))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1))`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(14, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (7, 7))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqBajij3YTZp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9092db5f-752c-4fe9-bddc-96521933d020"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_43 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_34 (Activation)   (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 26, 26, 10)        170       \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "activation_35 (Activation)   (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 13, 13, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_45 (Conv2D)           (None, 11, 11, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 11, 11, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_36 (Activation)   (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_46 (Conv2D)           (None, 9, 9, 14)          2030      \n",
            "_________________________________________________________________\n",
            "batch_normalization_32 (Batc (None, 9, 9, 14)          56        \n",
            "_________________________________________________________________\n",
            "activation_37 (Activation)   (None, 9, 9, 14)          0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 9, 9, 14)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_47 (Conv2D)           (None, 7, 7, 12)          1524      \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 7, 7, 12)          48        \n",
            "_________________________________________________________________\n",
            "activation_38 (Activation)   (None, 7, 7, 12)          0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 7, 7, 12)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_48 (Conv2D)           (None, 1, 1, 10)          5890      \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "activation_39 (Activation)   (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_49 (Conv2D)           (None, 1, 1, 10)          110       \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_40 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 11,692\n",
            "Trainable params: 11,516\n",
            "Non-trainable params: 176\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08zjwr_hYWuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scheduler(epoch, lr):\n",
        "    return round(0.003 * 1/(1 + 0.319 * epoch), 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6Rwdhh4YZT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=Adam(lr=0.003), \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXFzfYYHYbrL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "40f1f1fc-66af-4fd8-a9fe-34767bb717a5"
      },
      "source": [
        "\n",
        "model.fit(xtrain, ytrain, batch_size=32, nb_epoch=30, verbose=1, validation_data=(xtest, ytest), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 39s 651us/step - loss: 0.4204 - acc: 0.8932 - val_loss: 0.1077 - val_acc: 0.9769\n",
            "Epoch 2/30\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 36s 601us/step - loss: 0.1810 - acc: 0.9516 - val_loss: 0.0677 - val_acc: 0.9832\n",
            "Epoch 3/30\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 36s 602us/step - loss: 0.1465 - acc: 0.9597 - val_loss: 0.0506 - val_acc: 0.9869\n",
            "Epoch 4/30\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 36s 598us/step - loss: 0.1244 - acc: 0.9646 - val_loss: 0.0407 - val_acc: 0.9894\n",
            "Epoch 5/30\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 36s 597us/step - loss: 0.1159 - acc: 0.9670 - val_loss: 0.0382 - val_acc: 0.9893\n",
            "Epoch 6/30\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 36s 599us/step - loss: 0.1043 - acc: 0.9702 - val_loss: 0.0386 - val_acc: 0.9888\n",
            "Epoch 7/30\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 36s 598us/step - loss: 0.0998 - acc: 0.9717 - val_loss: 0.0384 - val_acc: 0.9887\n",
            "Epoch 8/30\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 36s 597us/step - loss: 0.0969 - acc: 0.9724 - val_loss: 0.0273 - val_acc: 0.9917\n",
            "Epoch 9/30\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 36s 597us/step - loss: 0.0924 - acc: 0.9741 - val_loss: 0.0279 - val_acc: 0.9926\n",
            "Epoch 10/30\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 36s 598us/step - loss: 0.0875 - acc: 0.9748 - val_loss: 0.0312 - val_acc: 0.9911\n",
            "Epoch 11/30\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 36s 600us/step - loss: 0.0862 - acc: 0.9757 - val_loss: 0.0287 - val_acc: 0.9924\n",
            "Epoch 12/30\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 36s 600us/step - loss: 0.0869 - acc: 0.9746 - val_loss: 0.0272 - val_acc: 0.9925\n",
            "Epoch 13/30\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 36s 600us/step - loss: 0.0825 - acc: 0.9772 - val_loss: 0.0281 - val_acc: 0.9926\n",
            "Epoch 14/30\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 36s 600us/step - loss: 0.0803 - acc: 0.9770 - val_loss: 0.0247 - val_acc: 0.9926\n",
            "Epoch 15/30\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 36s 599us/step - loss: 0.0818 - acc: 0.9759 - val_loss: 0.0233 - val_acc: 0.9930\n",
            "Epoch 16/30\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 36s 599us/step - loss: 0.0776 - acc: 0.9777 - val_loss: 0.0275 - val_acc: 0.9926\n",
            "Epoch 17/30\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 36s 598us/step - loss: 0.0813 - acc: 0.9770 - val_loss: 0.0261 - val_acc: 0.9928\n",
            "Epoch 18/30\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 36s 601us/step - loss: 0.0765 - acc: 0.9780 - val_loss: 0.0243 - val_acc: 0.9930\n",
            "Epoch 19/30\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 36s 602us/step - loss: 0.0774 - acc: 0.9779 - val_loss: 0.0249 - val_acc: 0.9925\n",
            "Epoch 20/30\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 36s 604us/step - loss: 0.0765 - acc: 0.9782 - val_loss: 0.0249 - val_acc: 0.9933\n",
            "Epoch 21/30\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "60000/60000 [==============================] - 36s 599us/step - loss: 0.0760 - acc: 0.9784 - val_loss: 0.0249 - val_acc: 0.9927\n",
            "Epoch 22/30\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "60000/60000 [==============================] - 36s 598us/step - loss: 0.0718 - acc: 0.9790 - val_loss: 0.0237 - val_acc: 0.9930\n",
            "Epoch 23/30\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "60000/60000 [==============================] - 36s 600us/step - loss: 0.0732 - acc: 0.9789 - val_loss: 0.0237 - val_acc: 0.9939\n",
            "Epoch 24/30\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "60000/60000 [==============================] - 36s 598us/step - loss: 0.0733 - acc: 0.9793 - val_loss: 0.0238 - val_acc: 0.9938\n",
            "Epoch 25/30\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "60000/60000 [==============================] - 36s 596us/step - loss: 0.0737 - acc: 0.9789 - val_loss: 0.0237 - val_acc: 0.9940\n",
            "Epoch 26/30\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "60000/60000 [==============================] - 36s 597us/step - loss: 0.0719 - acc: 0.9787 - val_loss: 0.0251 - val_acc: 0.9930\n",
            "Epoch 27/30\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "60000/60000 [==============================] - 36s 599us/step - loss: 0.0708 - acc: 0.9795 - val_loss: 0.0235 - val_acc: 0.9938\n",
            "Epoch 28/30\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "60000/60000 [==============================] - 36s 602us/step - loss: 0.0721 - acc: 0.9791 - val_loss: 0.0231 - val_acc: 0.9937\n",
            "Epoch 29/30\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "60000/60000 [==============================] - 36s 602us/step - loss: 0.0686 - acc: 0.9803 - val_loss: 0.0235 - val_acc: 0.9938\n",
            "Epoch 30/30\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "60000/60000 [==============================] - 36s 598us/step - loss: 0.0692 - acc: 0.9799 - val_loss: 0.0237 - val_acc: 0.9936\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb416bd12b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed0p9MmtYmdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(xtest, ytest, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pZc9te1c6p7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36587f57-caa7-4085-d499-d41c1452b26c"
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.023721380869857967, 0.9936]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqz6HMOdc7yK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}